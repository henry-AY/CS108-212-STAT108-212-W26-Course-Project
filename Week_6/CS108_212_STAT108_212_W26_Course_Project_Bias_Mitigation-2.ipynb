{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEovHtUoTG6K"
   },
   "source": [
    "# CS108/212 STAT108/212 W26 Course Project\n",
    "\n",
    "### Team Details\n",
    "\n",
    "- Teammate 1: Henry Yost\n",
    "- Teammate 2: Dmitry Sorokin\n",
    "- Teammate 3: Kyle Chahal\n",
    "- Teammate 4: Refugio Zepeda\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Milestone: Mitigating Bias\n",
    "For this project milestone, each teammate will implement bias mitigation strategies and assess pre and post bias mitigation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H61P2lQlNz1Q"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zcjl4O1GN24E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: ucimlrepo in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 6)) (0.0.7)\n",
      "Requirement already satisfied: fairlearn in /opt/anaconda3/lib/python3.13/site-packages (from -r ../requirements.txt (line 7)) (0.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->-r ../requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->-r ../requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/anaconda3/lib/python3.13/site-packages (from ucimlrepo->-r ../requirements.txt (line 6)) (2025.4.26)\n",
      "Requirement already satisfied: narwhals>=1.14.0 in /opt/anaconda3/lib/python3.13/site-packages (from fairlearn->-r ../requirements.txt (line 7)) (1.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->-r ../requirements.txt (line 1)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# [INSERT CODE HERE to install necessary packages]\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tXKU9aa5HPd"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CRQN7QJF5JUH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Add additional imports needed for your project here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V3zrVf11GUF"
   },
   "source": [
    "# Loading dataset\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Uimn7Sde1Jp2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n",
      "No. of samples: 48842\n",
      "No. of features: 14\n"
     ]
    }
   ],
   "source": [
    "# Load your selected dataset\n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "\n",
    "# variable information \n",
    "print(adult.variables)\n",
    "\n",
    "# Making our data a pandas df\n",
    "adult_clean = pd.concat([X, y], axis=1)\n",
    "\n",
    "sensitive_feature_colname = ['age', 'sex', 'race', 'marital-status'] # sensitive feature name\n",
    "#age, sex, race, (marital status), \n",
    "\n",
    "# Make sensitive features-based group labels\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "\n",
    "# Print some stats\n",
    "print(f\"No. of samples: {X.shape[0]}\")\n",
    "print(f\"No. of features: {X.shape[1]}\")\n",
    "#print(f\"Group Counts: {dict(collections.Counter(group_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq2dMuD87D0f"
   },
   "source": [
    "# Preparing dataset\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Mq3wYB1H7CXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples AFTER cleaning: 32561\n",
      "No. of features AFTER encoding: 12\n"
     ]
    }
   ],
   "source": [
    "# Some subset of following dataset preparation steps may be necessary depending on your dataset,\n",
    "# 1. Drop unnecessary features\n",
    "# 2. Handle missing data\n",
    "# 3. Encode categorical features\n",
    "# 4. Normalize numerical features\n",
    "# 5. Encode target (if your task is classification)\n",
    "\n",
    "\n",
    "\n",
    "#removing unwanted columns\n",
    "adult_clean = adult_clean.drop(columns = ['education', 'native-country'])\n",
    "#removing any empty values:\n",
    "adult_clean = adult_clean.dropna()\n",
    "#making income binary\n",
    "    #1 represents over 50 k\n",
    "mapping = {'>50K': 1, '<=50K': 0}\n",
    "adult_clean['income'] = adult_clean['income'].map(mapping)\n",
    "#updating sensitive labels\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "#factorizing non-numeric data:\n",
    "\n",
    "adult_clean['workclass_num'], unique_labels = pd.factorize(adult_clean['workclass'])\n",
    "adult_clean['marital-status_num'], unique_labels = pd.factorize(adult_clean['marital-status'])\n",
    "adult_clean['occupation_num'], unique_labels = pd.factorize(adult_clean['occupation'])\n",
    "adult_clean['relationship_num'], unique_labels = pd.factorize(adult_clean['relationship'])\n",
    "adult_clean['race_num'], unique_labels = pd.factorize(adult_clean['race'])\n",
    "#For sex, male is 1, female is 0\n",
    "mapping = {'Male': 1, 'Female': 0}\n",
    "adult_clean['sex'] = adult_clean['sex'].map(mapping)\n",
    "\n",
    "adult_clean = adult_clean.dropna()\n",
    "\n",
    "X = adult_clean[['age', 'workclass_num', 'fnlwgt', 'education-num', 'marital-status_num', 'occupation_num', 'relationship_num', 'race_num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']]\n",
    "y = adult_clean[['income']]\n",
    "\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "\n",
    "\n",
    "# Note: X and y have been modified before the following lines of code!\n",
    "print(f\"No. of samples AFTER cleaning: {X.shape[0]}\")\n",
    "assert X.shape[0] == y.shape[0] == group_labels.shape[0] ## Ensure that the target and group_labels have been updated if some samples were removed during cleaning.\n",
    "print(f\"No. of features AFTER encoding: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1xfwjUT3nJ0"
   },
   "source": [
    "# Getting training and testing sets\n",
    "\n",
    "Note: Train-test split is made **ONCE** to obtain the _training set_ and the _testing set_ and every teammate will use the training set to train their baseline model and test the trained model using the testing set. **NEVER** modify the testing set once it has been created.\n",
    "Therefore, the following code cell does not need to be edited.\n",
    "\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "udqlgotu5a5m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training samples: 26048\n",
      "No. of testing samples: 6513\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, \\\n",
    "  y_train, y_test, \\\n",
    "    group_labels_train, group_labels_test = train_test_split(X, y, group_labels,\n",
    "                                                             test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"No. of training samples: {X_train.shape[0]}\")\n",
    "print(f\"No. of testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Delete X, y and group_label variables to make sure they are not used later on.\n",
    "del X\n",
    "del y\n",
    "del group_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stfLke4NBA-B"
   },
   "source": [
    "# Setting up evaluation metrics\n",
    "Note: The same evaluation function will be used by all teammates.\n",
    "\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RxX61lMDA50u"
   },
   "outputs": [],
   "source": [
    "# double importing just in case\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(y_test, y_pred, g_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of your trained model on the testing set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : array-like\n",
    "    The true targets of the testing set.\n",
    "    y_pred : array-like\n",
    "    The predicted targets of the testing set.\n",
    "    g_labels : array-like\n",
    "    The group labels of the testing set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "    A dictionary containing the evaluation results.\n",
    "    \n",
    "    Example:\n",
    "    For classification task, the task-specific performance metrics like {'accuracy': <value>, 'f1_score': <value>, ...}\n",
    "    and fairness metrics like {'demographic_parity': <value>, 'equalized_odds': <value>, ...}.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # force them to be arrays just in case, so we don't have an error\n",
    "    y_test = np.asarray(y_test).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    g_labels = np.asarray(g_labels).ravel()\n",
    "    \n",
    "    # Note: These metrics will be calculated for - 1. the full testing set, 2. individual groups.\n",
    "    # Task-specific performance metrics\n",
    "\n",
    "    global_accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(f\"Global Accuracy score of: {global_accuracy}\")\n",
    "    results[\"accuracy_overall\"] = global_accuracy\n",
    "\n",
    "    global_f1 = f1_score(y_test, y_pred)\n",
    "    # print(f\"Global f1 score of: {global_f1}\")\n",
    "    results[\"f1_overall\"] = global_f1\n",
    "\n",
    "    results[\"accuracy_by_group\"] = {}\n",
    "    results[\"f1_by_group\"] = {}\n",
    "\n",
    "    for g in np.unique(g_labels):\n",
    "        mask = (g_labels == g)\n",
    "        y_test_g = y_test[mask]\n",
    "        y_pred_g = y_pred[mask]\n",
    "\n",
    "        results[\"accuracy_by_group\"][g] = accuracy_score(y_test_g, y_pred_g)\n",
    "        results[\"f1_by_group\"][g] = f1_score(y_test_g, y_pred_g, pos_label=1, zero_division=0)\n",
    "    \n",
    "    # Fairness metric:\n",
    "    # The fairness metric we will be using is equalied odds, because: Equalized odds requires the TPR and FPR are equal accross all protected groups.\n",
    "\n",
    "    eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=g_labels, method='between_groups')\n",
    "    # print(f\"Equalized Odds Difference: {eo_diff}\")\n",
    "    results['eo_diff'] = eo_diff\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My_giZbvpFEK"
   },
   "source": [
    "# Training baseline models (INDIVIDUAL CONTRIBUTION)\n",
    "_(minor modifications from previous milestone)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kK2P9uZnIKGf"
   },
   "outputs": [],
   "source": [
    "## A place to save all teammates's baseline results\n",
    "all_baseline_results = [] ## DO NOT EDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "400FpWHZ_z0S"
   },
   "source": [
    "## Teammate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code that is used by all teammates, seperated so we dont re-run it multiple times\n",
    "#defining sensitive cols\n",
    "age_bins = [0, 25, 45, 65, 120]\n",
    "age_labels = ['Under_25', '25_to_45', '46_to_65', 'Over_65']\n",
    "\n",
    "# 2. Bin the ages from X_test ON THE FLY into a temporary variable\n",
    "binned_age_test = pd.cut(X_test['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# 3. Create your group_labels_test by combining the temporary binned ages \n",
    "# with the other numerical columns in X_test\n",
    "group_labels_test = binned_age_test.astype(str) + '_' + \\\n",
    "                    X_test['sex'].astype(str) + '_' + \\\n",
    "                    X_test['race_num'].astype(str)\n",
    "\n",
    "#normalizing training data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BjKUAk4I_4DQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:  1  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  2  Equalized Odds Diff:  0.6153846153846154\n",
      "Neighbors:  3  Equalized Odds Diff:  0.8\n",
      "Neighbors:  4  Equalized Odds Diff:  0.6153846153846154\n",
      "Neighbors:  5  Equalized Odds Diff:  0.8\n",
      "Neighbors:  6  Equalized Odds Diff:  0.6923076923076923\n",
      "Neighbors:  7  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  8  Equalized Odds Diff:  0.6923076923076923\n",
      "Neighbors:  9  Equalized Odds Diff:  0.8\n",
      "Neighbors:  10  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  11  Equalized Odds Diff:  0.8461538461538461\n",
      "Neighbors:  12  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  13  Equalized Odds Diff:  0.9230769230769231\n",
      "Neighbors:  14  Equalized Odds Diff:  0.9230769230769231\n",
      "Neighbors:  15  Equalized Odds Diff:  0.9230769230769231\n",
      "Neighbors:  16  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  17  Equalized Odds Diff:  0.9230769230769231\n",
      "Neighbors:  18  Equalized Odds Diff:  0.7692307692307693\n",
      "Neighbors:  19  Equalized Odds Diff:  0.8461538461538461\n",
      "Neighbors:  20  Equalized Odds Diff:  0.7692307692307693\n",
      "Optimal number of neighbors:  2 . Optimal EO_diff:  0.6153846153846154\n",
      "{'accuracy_by_group': {'25_to_45_0_0': 0.8622448979591837,\n",
      "                       '25_to_45_0_1': 0.9818181818181818,\n",
      "                       '25_to_45_0_2': 0.8055555555555556,\n",
      "                       '25_to_45_0_3': 1.0,\n",
      "                       '25_to_45_0_4': 1.0,\n",
      "                       '25_to_45_1_0': 0.7528089887640449,\n",
      "                       '25_to_45_1_1': 0.845679012345679,\n",
      "                       '25_to_45_1_2': 0.7045454545454546,\n",
      "                       '25_to_45_1_3': 0.8260869565217391,\n",
      "                       '25_to_45_1_4': 0.8421052631578947,\n",
      "                       '46_to_65_0_0': 0.8519417475728155,\n",
      "                       '46_to_65_0_1': 0.9375,\n",
      "                       '46_to_65_0_2': 0.9,\n",
      "                       '46_to_65_0_3': 0.6666666666666666,\n",
      "                       '46_to_65_0_4': 1.0,\n",
      "                       '46_to_65_1_0': 0.6898395721925134,\n",
      "                       '46_to_65_1_1': 0.8076923076923077,\n",
      "                       '46_to_65_1_2': 0.7272727272727273,\n",
      "                       '46_to_65_1_3': 0.75,\n",
      "                       '46_to_65_1_4': 0.7777777777777778,\n",
      "                       'Over_65_0_0': 0.9552238805970149,\n",
      "                       'Over_65_0_1': 1.0,\n",
      "                       'Over_65_0_2': 1.0,\n",
      "                       'Over_65_0_4': 1.0,\n",
      "                       'Over_65_1_0': 0.8148148148148148,\n",
      "                       'Over_65_1_1': 0.9090909090909091,\n",
      "                       'Over_65_1_2': 0.75,\n",
      "                       'Over_65_1_3': 1.0,\n",
      "                       'Under_25_0_0': 0.9782608695652174,\n",
      "                       'Under_25_0_1': 1.0,\n",
      "                       'Under_25_0_2': 0.9166666666666666,\n",
      "                       'Under_25_0_3': 1.0,\n",
      "                       'Under_25_0_4': 1.0,\n",
      "                       'Under_25_1_0': 0.9802130898021308,\n",
      "                       'Under_25_1_1': 1.0,\n",
      "                       'Under_25_1_2': 0.9473684210526315,\n",
      "                       'Under_25_1_3': 1.0,\n",
      "                       'Under_25_1_4': 1.0},\n",
      " 'accuracy_overall': 0.8225088284968525,\n",
      " 'eo_diff': 0.6153846153846154,\n",
      " 'experiment_type': 'baseline',\n",
      " 'f1_by_group': {'25_to_45_0_0': 0.425531914893617,\n",
      "                 '25_to_45_0_1': 0.6666666666666666,\n",
      "                 '25_to_45_0_2': 0.2222222222222222,\n",
      "                 '25_to_45_0_3': 0.0,\n",
      "                 '25_to_45_0_4': 0.0,\n",
      "                 '25_to_45_1_0': 0.5310077519379846,\n",
      "                 '25_to_45_1_1': 0.5098039215686274,\n",
      "                 '25_to_45_1_2': 0.59375,\n",
      "                 '25_to_45_1_3': 0.5,\n",
      "                 '25_to_45_1_4': 0.0,\n",
      "                 '46_to_65_0_0': 0.41904761904761906,\n",
      "                 '46_to_65_0_1': 0.0,\n",
      "                 '46_to_65_0_2': 0.0,\n",
      "                 '46_to_65_0_3': 0.0,\n",
      "                 '46_to_65_0_4': 0.0,\n",
      "                 '46_to_65_1_0': 0.6063348416289592,\n",
      "                 '46_to_65_1_1': 0.5454545454545454,\n",
      "                 '46_to_65_1_2': 0.7272727272727273,\n",
      "                 '46_to_65_1_3': 0.0,\n",
      "                 '46_to_65_1_4': 0.5,\n",
      "                 'Over_65_0_0': 0.0,\n",
      "                 'Over_65_0_1': 0.0,\n",
      "                 'Over_65_0_2': 0.0,\n",
      "                 'Over_65_0_4': 0.0,\n",
      "                 'Over_65_1_0': 0.5454545454545454,\n",
      "                 'Over_65_1_1': 0.0,\n",
      "                 'Over_65_1_2': 0.0,\n",
      "                 'Over_65_1_3': 0.0,\n",
      "                 'Under_25_0_0': 0.16666666666666666,\n",
      "                 'Under_25_0_1': 0.0,\n",
      "                 'Under_25_0_2': 0.0,\n",
      "                 'Under_25_0_3': 0.0,\n",
      "                 'Under_25_0_4': 0.0,\n",
      "                 'Under_25_1_0': 0.38095238095238093,\n",
      "                 'Under_25_1_1': 0.0,\n",
      "                 'Under_25_1_2': 0.0,\n",
      "                 'Under_25_1_3': 0.0,\n",
      "                 'Under_25_1_4': 0.0},\n",
      " 'f1_overall': 0.5405405405405406,\n",
      " 'mitigation_strategy': 'NONE',\n",
      " 'predictor_model': 'KNN',\n",
      " 'teammate': 'Dmitry'}\n"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "# Deciding to use a KNN model\n",
    "#\n",
    "\n",
    "#finding optimal number of neighbors from 1 to 10, arbitrarily chosen, to limit processing time.\n",
    "optimal_n = 0\n",
    "optimal_n_score = 0\n",
    "\n",
    "for i in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, np.asarray(y_train).ravel())\n",
    "    predictions = knn.predict(X_test)\n",
    "    model_score = eo_diff = equalized_odds_difference(y_test, predictions, sensitive_features=group_labels_test, method='between_groups')\n",
    "    #knn.score(X_test, y_test)\n",
    "\n",
    "    if(0 == optimal_n):\n",
    "        optimal_n = i\n",
    "        optimal_n_score = model_score\n",
    "    elif(model_score < optimal_n_score):\n",
    "        optimal_n = i\n",
    "        optimal_n_score = model_score\n",
    "\n",
    "    print('Neighbors: ', i, ' Equalized Odds Diff: ', model_score)\n",
    "\n",
    "#Making the actual model:\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=optimal_n)\n",
    "KNN_model.fit(X_train, np.asarray(y_train).ravel())\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = KNN_model.predict(X_test)\n",
    "print(\"Optimal number of neighbors: \", optimal_n, \". Optimal EO_diff: \", optimal_n_score)\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Dmitry'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'KNN' #[INSERT MODEL NAME HERE]\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis / Interpretation for KNN Model:**\n",
    "\n",
    "Looking at the results I got after training and optimizing the KNN model, we see that our optimal number of neighbors, for maximizing equalized odds is 2. Moreover, we see that it scores fairly well for the accuracy when divided by groups. The lowest accuracy we get is for the 25 to 45 group with about 80.6% accruacy. \n",
    "\n",
    "However, our overall f1 score is fairly low at around 54%. This means that while we may be getting a minimal equalized odds difference, our overall accuracy is lower than what we would like. In a previous iteration, I focused on maximizing the accuracy of the model, however, that led to a detrimental increase in our equalized odds difference, meaning that the model was inherently baised.\n",
    "\n",
    "In my opinion, the hit to accuracy, for instead having a more fair model is almost justified for this case. I would ideally hope for better accuracy, hopefully post mitigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VYWPshD_zlw"
   },
   "source": [
    "## Teammate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dgDw0Ta7_7FT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_by_group': {'25_to_45_0_0': 0.8801020408163265,\n",
      "                       '25_to_45_0_1': 0.9757575757575757,\n",
      "                       '25_to_45_0_2': 0.7777777777777778,\n",
      "                       '25_to_45_0_3': 1.0,\n",
      "                       '25_to_45_0_4': 1.0,\n",
      "                       '25_to_45_1_0': 0.7951991828396323,\n",
      "                       '25_to_45_1_1': 0.8395061728395061,\n",
      "                       '25_to_45_1_2': 0.8068181818181818,\n",
      "                       '25_to_45_1_3': 0.9130434782608695,\n",
      "                       '25_to_45_1_4': 0.8421052631578947,\n",
      "                       '46_to_65_0_0': 0.8907766990291263,\n",
      "                       '46_to_65_0_1': 0.96875,\n",
      "                       '46_to_65_0_2': 0.8,\n",
      "                       '46_to_65_0_3': 0.8333333333333334,\n",
      "                       '46_to_65_0_4': 1.0,\n",
      "                       '46_to_65_1_0': 0.7156862745098039,\n",
      "                       '46_to_65_1_1': 0.8846153846153846,\n",
      "                       '46_to_65_1_2': 0.7272727272727273,\n",
      "                       '46_to_65_1_3': 0.625,\n",
      "                       '46_to_65_1_4': 0.7777777777777778,\n",
      "                       'Over_65_0_0': 0.9552238805970149,\n",
      "                       'Over_65_0_1': 1.0,\n",
      "                       'Over_65_0_2': 1.0,\n",
      "                       'Over_65_0_4': 1.0,\n",
      "                       'Over_65_1_0': 0.7777777777777778,\n",
      "                       'Over_65_1_1': 0.9090909090909091,\n",
      "                       'Over_65_1_2': 0.75,\n",
      "                       'Over_65_1_3': 1.0,\n",
      "                       'Under_25_0_0': 0.9847826086956522,\n",
      "                       'Under_25_0_1': 1.0,\n",
      "                       'Under_25_0_2': 0.9166666666666666,\n",
      "                       'Under_25_0_3': 0.9,\n",
      "                       'Under_25_0_4': 1.0,\n",
      "                       'Under_25_1_0': 0.9771689497716894,\n",
      "                       'Under_25_1_1': 0.9795918367346939,\n",
      "                       'Under_25_1_2': 0.9473684210526315,\n",
      "                       'Under_25_1_3': 1.0,\n",
      "                       'Under_25_1_4': 1.0},\n",
      " 'accuracy_overall': 0.8456932289267619,\n",
      " 'eo_diff': 0.8461538461538461,\n",
      " 'experiment_type': 'baseline',\n",
      " 'f1_by_group': {'25_to_45_0_0': 0.5252525252525253,\n",
      "                 '25_to_45_0_1': 0.6,\n",
      "                 '25_to_45_0_2': 0.5,\n",
      "                 '25_to_45_0_3': 0.0,\n",
      "                 '25_to_45_0_4': 0.0,\n",
      "                 '25_to_45_1_0': 0.6331198536139067,\n",
      "                 '25_to_45_1_1': 0.5185185185185185,\n",
      "                 '25_to_45_1_2': 0.7848101265822784,\n",
      "                 '25_to_45_1_3': 0.8,\n",
      "                 '25_to_45_1_4': 0.4,\n",
      "                 '46_to_65_0_0': 0.5945945945945946,\n",
      "                 '46_to_65_0_1': 0.6666666666666666,\n",
      "                 '46_to_65_0_2': 0.0,\n",
      "                 '46_to_65_0_3': 0.6666666666666666,\n",
      "                 '46_to_65_0_4': 0.0,\n",
      "                 '46_to_65_1_0': 0.63121387283237,\n",
      "                 '46_to_65_1_1': 0.7428571428571429,\n",
      "                 '46_to_65_1_2': 0.7857142857142857,\n",
      "                 '46_to_65_1_3': 0.0,\n",
      "                 '46_to_65_1_4': 0.6666666666666666,\n",
      "                 'Over_65_0_0': 0.4,\n",
      "                 'Over_65_0_1': 0.0,\n",
      "                 'Over_65_0_2': 0.0,\n",
      "                 'Over_65_0_4': 0.0,\n",
      "                 'Over_65_1_0': 0.6153846153846154,\n",
      "                 'Over_65_1_1': 0.0,\n",
      "                 'Over_65_1_2': 0.0,\n",
      "                 'Over_65_1_3': 0.0,\n",
      "                 'Under_25_0_0': 0.46153846153846156,\n",
      "                 'Under_25_0_1': 0.0,\n",
      "                 'Under_25_0_2': 0.0,\n",
      "                 'Under_25_0_3': 0.0,\n",
      "                 'Under_25_0_4': 0.0,\n",
      "                 'Under_25_1_0': 0.5161290322580645,\n",
      "                 'Under_25_1_1': 0.0,\n",
      "                 'Under_25_1_2': 0.0,\n",
      "                 'Under_25_1_3': 0.0,\n",
      "                 'Under_25_1_4': 0.0},\n",
      " 'f1_overall': 0.6217538577342868,\n",
      " 'mitigation_strategy': 'NONE',\n",
      " 'predictor_model': 'Decision Tree',\n",
      " 'teammate': 'Kyle'}\n"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "decisionTree_Model = DecisionTreeClassifier(random_state = 44,\n",
    "                                            max_depth = 5,\n",
    "                                            min_samples_leaf = 20)\n",
    "\n",
    "decisionTree_Model.fit(X_train, np.asarray(y_train).ravel())\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = decisionTree_Model.predict(X_test)\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Kyle'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'Decision Tree' #[INSERT MODEL NAME HERE]\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis / Interpretation for Decision Tree Model:**\n",
    "\n",
    "After looking at the global performance metrics for my Decision Tree Model, we see that the overall F1 score is around 0.622, which is quite a but higher than that of KNN and Linear Model. The decision trees seem to have a better balance between its precision and recall, which may lead to it doing a better job at identifying whether someone has a >50k income. \n",
    "\n",
    "When looking at the different subgroups' accuracy, we see that the performance varies a bit, but stays generally strong across most of the demographic combinations. A majority of the subgroups accuracy falls between 0.77 and 0.97, with a few of them reaching 1.0. The lower accuracies appear within certain 46-65 subgroups, suggesting some inconsistencies in the predictive performance for the specific task at hand. \n",
    "The subgroups that have 1.0's for their accuracy should be treated with caution, cause it may be caused by some bias in the model itself.\n",
    "\n",
    "Overall the model seems to do a pretty good job, but the flexibility of the model allows for some fairness concerns to arise due to the subgroup variability and possible overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bq--e_8_7o2"
   },
   "source": [
    "## Teammate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j9DspEoL_-EV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_by_group': {'25_to_45_0_0': 0.8418367346938775,\n",
      "                       '25_to_45_0_1': 0.9757575757575757,\n",
      "                       '25_to_45_0_2': 0.7777777777777778,\n",
      "                       '25_to_45_0_3': 1.0,\n",
      "                       '25_to_45_0_4': 1.0,\n",
      "                       '25_to_45_1_0': 0.7379979570990807,\n",
      "                       '25_to_45_1_1': 0.8271604938271605,\n",
      "                       '25_to_45_1_2': 0.625,\n",
      "                       '25_to_45_1_3': 0.8260869565217391,\n",
      "                       '25_to_45_1_4': 0.8421052631578947,\n",
      "                       '46_to_65_0_0': 0.8446601941747572,\n",
      "                       '46_to_65_0_1': 0.921875,\n",
      "                       '46_to_65_0_2': 0.9,\n",
      "                       '46_to_65_0_3': 0.6666666666666666,\n",
      "                       '46_to_65_0_4': 1.0,\n",
      "                       '46_to_65_1_0': 0.6898395721925134,\n",
      "                       '46_to_65_1_1': 0.7948717948717948,\n",
      "                       '46_to_65_1_2': 0.6818181818181818,\n",
      "                       '46_to_65_1_3': 0.75,\n",
      "                       '46_to_65_1_4': 0.6666666666666666,\n",
      "                       'Over_65_0_0': 0.9402985074626866,\n",
      "                       'Over_65_0_1': 1.0,\n",
      "                       'Over_65_0_2': 1.0,\n",
      "                       'Over_65_0_4': 1.0,\n",
      "                       'Over_65_1_0': 0.7703703703703704,\n",
      "                       'Over_65_1_1': 0.7272727272727273,\n",
      "                       'Over_65_1_2': 0.75,\n",
      "                       'Over_65_1_3': 1.0,\n",
      "                       'Under_25_0_0': 0.9826086956521739,\n",
      "                       'Under_25_0_1': 1.0,\n",
      "                       'Under_25_0_2': 0.9166666666666666,\n",
      "                       'Under_25_0_3': 1.0,\n",
      "                       'Under_25_0_4': 1.0,\n",
      "                       'Under_25_1_0': 0.9771689497716894,\n",
      "                       'Under_25_1_1': 1.0,\n",
      "                       'Under_25_1_2': 0.9473684210526315,\n",
      "                       'Under_25_1_3': 1.0,\n",
      "                       'Under_25_1_4': 1.0},\n",
      " 'accuracy_overall': 0.8113004759711346,\n",
      " 'eo_diff': 0.7428571428571429,\n",
      " 'experiment_type': 'baseline',\n",
      " 'f1_by_group': {'25_to_45_0_0': 0.10144927536231885,\n",
      "                 '25_to_45_0_1': 0.3333333333333333,\n",
      "                 '25_to_45_0_2': 0.0,\n",
      "                 '25_to_45_0_3': 0.0,\n",
      "                 '25_to_45_0_4': 0.0,\n",
      "                 '25_to_45_1_0': 0.3971797884841363,\n",
      "                 '25_to_45_1_1': 0.3,\n",
      "                 '25_to_45_1_2': 0.37735849056603776,\n",
      "                 '25_to_45_1_3': 0.5,\n",
      "                 '25_to_45_1_4': 0.0,\n",
      "                 '46_to_65_0_0': 0.3191489361702128,\n",
      "                 '46_to_65_0_1': 0.0,\n",
      "                 '46_to_65_0_2': 0.0,\n",
      "                 '46_to_65_0_3': 0.0,\n",
      "                 '46_to_65_0_4': 0.0,\n",
      "                 '46_to_65_1_0': 0.5876777251184834,\n",
      "                 '46_to_65_1_1': 0.5294117647058824,\n",
      "                 '46_to_65_1_2': 0.6956521739130435,\n",
      "                 '46_to_65_1_3': 0.0,\n",
      "                 '46_to_65_1_4': 0.4,\n",
      "                 'Over_65_0_0': 0.0,\n",
      "                 'Over_65_0_1': 0.0,\n",
      "                 'Over_65_0_2': 0.0,\n",
      "                 'Over_65_0_4': 0.0,\n",
      "                 'Over_65_1_0': 0.6265060240963856,\n",
      "                 'Over_65_1_1': 0.0,\n",
      "                 'Over_65_1_2': 0.0,\n",
      "                 'Over_65_1_3': 0.0,\n",
      "                 'Under_25_0_0': 0.0,\n",
      "                 'Under_25_0_1': 0.0,\n",
      "                 'Under_25_0_2': 0.0,\n",
      "                 'Under_25_0_3': 0.0,\n",
      "                 'Under_25_0_4': 0.0,\n",
      "                 'Under_25_1_0': 0.0,\n",
      "                 'Under_25_1_1': 0.0,\n",
      "                 'Under_25_1_2': 0.0,\n",
      "                 'Under_25_1_3': 0.0,\n",
      "                 'Under_25_1_4': 0.0},\n",
      " 'f1_overall': 0.4496193461710703,\n",
      " 'mitigation_strategy': 'NONE',\n",
      " 'predictor_model': 'Linear model',\n",
      " 'teammate': 'Teammate 3'}\n"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "# Linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_numerical = linear_model.predict(X_test)\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = (y_pred_numerical >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Teammate 3'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'Linear model'\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis / Interpretation for Linear Model:**\n",
    "\n",
    "Based on the global metrics, the LM has an accuracy of 0.811, which is quite strong for a rigid LM. However, the f1 score is very low relative to accuracy, 0.45 respectively. This suggests class imbalance, as the model predicts the majority class much more frequently than the minority class (>50k income). This is a logical, as an LM is rigid, and the treshold can heavily skew the f1 score.\n",
    "\n",
    "Looking at accuracy per group, it varies quite a bit, from a min of 0.625 and a max of 1.0. Contrarily, f1 score per group is mostly 0, which brings us back to the imbalance issue mentioned previously. The model predicts the majority class almost exclusively.\n",
    "\n",
    "Lastly, looking at the fairness metrics, the equalized odds score is 0.743. Which is very high, suggesting that the model is very biased accross sensitive subgroups. This is something we need to consider, when looking at mitigating the bias in our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXm38f8ZABN3"
   },
   "source": [
    "## Teammate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "g-GVw7gOADZx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_by_group': {'25_to_45_0_0': 0.8469387755102041,\n",
      "                       '25_to_45_0_1': 0.9818181818181818,\n",
      "                       '25_to_45_0_2': 0.7777777777777778,\n",
      "                       '25_to_45_0_3': 1.0,\n",
      "                       '25_to_45_0_4': 1.0,\n",
      "                       '25_to_45_1_0': 0.7604698672114403,\n",
      "                       '25_to_45_1_1': 0.845679012345679,\n",
      "                       '25_to_45_1_2': 0.7159090909090909,\n",
      "                       '25_to_45_1_3': 0.9130434782608695,\n",
      "                       '25_to_45_1_4': 0.8947368421052632,\n",
      "                       '46_to_65_0_0': 0.8616504854368932,\n",
      "                       '46_to_65_0_1': 0.953125,\n",
      "                       '46_to_65_0_2': 0.9,\n",
      "                       '46_to_65_0_3': 0.8333333333333334,\n",
      "                       '46_to_65_0_4': 1.0,\n",
      "                       '46_to_65_1_0': 0.713903743315508,\n",
      "                       '46_to_65_1_1': 0.8333333333333334,\n",
      "                       '46_to_65_1_2': 0.7272727272727273,\n",
      "                       '46_to_65_1_3': 0.75,\n",
      "                       '46_to_65_1_4': 0.6666666666666666,\n",
      "                       'Over_65_0_0': 0.9253731343283582,\n",
      "                       'Over_65_0_1': 1.0,\n",
      "                       'Over_65_0_2': 1.0,\n",
      "                       'Over_65_0_4': 1.0,\n",
      "                       'Over_65_1_0': 0.725925925925926,\n",
      "                       'Over_65_1_1': 0.7272727272727273,\n",
      "                       'Over_65_1_2': 0.75,\n",
      "                       'Over_65_1_3': 1.0,\n",
      "                       'Under_25_0_0': 0.9804347826086957,\n",
      "                       'Under_25_0_1': 1.0,\n",
      "                       'Under_25_0_2': 0.9166666666666666,\n",
      "                       'Under_25_0_3': 1.0,\n",
      "                       'Under_25_0_4': 1.0,\n",
      "                       'Under_25_1_0': 0.9802130898021308,\n",
      "                       'Under_25_1_1': 0.9795918367346939,\n",
      "                       'Under_25_1_2': 0.9473684210526315,\n",
      "                       'Under_25_1_3': 1.0,\n",
      "                       'Under_25_1_4': 1.0},\n",
      " 'accuracy_overall': 0.8261937663135268,\n",
      " 'eo_diff': 0.8333333333333334,\n",
      " 'experiment_type': 'baseline',\n",
      " 'f1_by_group': {'25_to_45_0_0': 0.24050632911392406,\n",
      "                 '25_to_45_0_1': 0.5714285714285714,\n",
      "                 '25_to_45_0_2': 0.0,\n",
      "                 '25_to_45_0_3': 0.0,\n",
      "                 '25_to_45_0_4': 0.0,\n",
      "                 '25_to_45_1_0': 0.5295887662988967,\n",
      "                 '25_to_45_1_1': 0.4444444444444444,\n",
      "                 '25_to_45_1_2': 0.5901639344262295,\n",
      "                 '25_to_45_1_3': 0.8333333333333334,\n",
      "                 '25_to_45_1_4': 0.5,\n",
      "                 '46_to_65_0_0': 0.45714285714285713,\n",
      "                 '46_to_65_0_1': 0.4,\n",
      "                 '46_to_65_0_2': 0.0,\n",
      "                 '46_to_65_0_3': 0.6666666666666666,\n",
      "                 '46_to_65_0_4': 0.0,\n",
      "                 '46_to_65_1_0': 0.6595970307529162,\n",
      "                 '46_to_65_1_1': 0.6829268292682927,\n",
      "                 '46_to_65_1_2': 0.75,\n",
      "                 '46_to_65_1_3': 0.0,\n",
      "                 '46_to_65_1_4': 0.4,\n",
      "                 'Over_65_0_0': 0.2857142857142857,\n",
      "                 'Over_65_0_1': 0.0,\n",
      "                 'Over_65_0_2': 0.0,\n",
      "                 'Over_65_0_4': 0.0,\n",
      "                 'Over_65_1_0': 0.6105263157894737,\n",
      "                 'Over_65_1_1': 0.0,\n",
      "                 'Over_65_1_2': 0.0,\n",
      "                 'Over_65_1_3': 0.0,\n",
      "                 'Under_25_0_0': 0.0,\n",
      "                 'Under_25_0_1': 0.0,\n",
      "                 'Under_25_0_2': 0.0,\n",
      "                 'Under_25_0_3': 0.0,\n",
      "                 'Under_25_0_4': 0.0,\n",
      "                 'Under_25_1_0': 0.3157894736842105,\n",
      "                 'Under_25_1_1': 0.0,\n",
      "                 'Under_25_1_2': 0.0,\n",
      "                 'Under_25_1_3': 0.0,\n",
      "                 'Under_25_1_4': 0.0},\n",
      " 'f1_overall': 0.5574667709147771,\n",
      " 'mitigation_strategy': 'NONE',\n",
      " 'predictor_model': 'Logistic Regression',\n",
      " 'teammate': 'Refugio'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "# [INSERT YOUR CODE HERE]\n",
    "logreg = LogisticRegression(\n",
    "    C=1.0, \n",
    "    solver =\"lbfgs\",\n",
    "    max_iter= 1000 \n",
    ")\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Refugio'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'Logistic Regression'\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis / Interpretation for Linear Model:**\n",
    "\n",
    "Based on the global metrics, our logistic regresion model has a 0.8261 accurary score, which is suffecicently strong. However, the f1 score is very low, 0.5575 respectively. This suggests class imbalance, as the model predicts will for people whom make more than 50k/year since they have a larger subgroup in the dataset. \n",
    "\n",
    "Looking at accuracy per group, it varies quite a bit, from a min of 0.666 and a max of 1.0. This shows a high variabily within the predictions as a margin difference of 0.33 is quite large to have when compaing max - min. \n",
    "\n",
    "Lastly, looking at the fairness metrics, the equalized odds score is 0.833. Which is extremely high, suggesting that the model treats group drastically different when making mistakes in predicting. All of these metrics are things to consider when implementing our mitigation bias strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lq5X0Xb5eWA"
   },
   "source": [
    "# Mitigating Bias (INDIVIDUAL CONTRIBUTION)\n",
    "\n",
    "_(new in this milestone)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LwfT5Uv9I0j6"
   },
   "outputs": [],
   "source": [
    "## A place to save all teammates' post-mitigation results\n",
    "all_mitigated_results = [] ## DO NOT EDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmQrfFvn6E85"
   },
   "source": [
    "## Teammate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CZhAOHFB5lzh"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6513, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y_pred_mitigated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# [INSERT CODE HERE]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate testing set predictions using evaluate_model()\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m results_mitigated \u001b[38;5;241m=\u001b[39m evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save your results to all_mitigated_results\u001b[39;00m\n\u001b[1;32m     15\u001b[0m results_mitigated[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteammate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeammate 1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[20], line 36\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(y_test, y_pred, g_labels)\u001b[0m\n\u001b[1;32m     31\u001b[0m g_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(g_labels)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Note: These metrics will be calculated for - 1. the full testing set, 2. individual groups.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Task-specific performance metrics\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m global_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# print(f\"Global Accuracy score of: {global_accuracy}\")\u001b[39;00m\n\u001b[1;32m     38\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_overall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m global_accuracy\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6513, 1]"
     ]
    }
   ],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 1'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "pprint(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X05x8kjr6KrH"
   },
   "source": [
    "### Teammate 1's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLB2ggUCBen_"
   },
   "source": [
    "## Teammate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtbctHpBBgna"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 2'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmwKk9f2BlaM"
   },
   "source": [
    "### Teammate 2's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUpxtxuUCF_I"
   },
   "source": [
    "## Teammate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KlNlq7lCInQ"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 3 - Henry'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YN7oELoCKmF"
   },
   "source": [
    "### Teammate 3's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qNMlhiECMcD"
   },
   "source": [
    "## Teammate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-JCVhRdCPSw"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 4'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnJcnOevCSm-"
   },
   "source": [
    "### Teammate 4's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4LK5WRD7LvV"
   },
   "source": [
    "# Conclusions\n",
    "_(new in this milestone)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ZAgZJYf7F70N",
    "outputId": "42dcf95b-699c-4037-bb88-2c604648d111"
   },
   "outputs": [],
   "source": [
    "# Collect all the results in one table.\n",
    "overall_results = pd.concat([pd.DataFrame(all_baseline_results), pd.DataFrame(all_mitigated_results)])\n",
    "overall_results ## Note: The table displayed below in this starter notebook is for your reference, your team's table will be slightly different (e.g. different metrics, no.of sensitive attribute-based groups, actual values, etc.) upon successful completion of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds54O8vGGAEw"
   },
   "source": [
    "[Briefly describe overall findings and conclusions here. Which mitigation strategy resulted in most improvement? Which resulted in the least improvement? Visualize the results with some informative plots. (Hint: Use the `overall_results` table).]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-8NLvIOsPL-"
   },
   "source": [
    "# References\n",
    "\n",
    "[List the references you used to complete this milestone here.]\n",
    "- Teammate 1:\n",
    "- Teammate 2:\n",
    "- Teammate 3:\n",
    "- Teammate 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV3LsIXqKAg1"
   },
   "source": [
    "# Disclosures\n",
    "\n",
    "[Disclose use of generative AI and similar tools here.]\n",
    "- Teammate 1:\n",
    "- Teammate 2:\n",
    "- Teammate 3:\n",
    "- Teammate 4:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7V3zrVf11GUF",
    "zq2dMuD87D0f",
    "h1xfwjUT3nJ0",
    "stfLke4NBA-B",
    "400FpWHZ_z0S",
    "_VYWPshD_zlw",
    "_Bq--e_8_7o2",
    "DXm38f8ZABN3",
    "ZLB2ggUCBen_",
    "ZUpxtxuUCF_I",
    "3qNMlhiECMcD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
