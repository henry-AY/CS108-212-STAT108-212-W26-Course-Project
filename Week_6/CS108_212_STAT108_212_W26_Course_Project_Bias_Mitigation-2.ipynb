{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEovHtUoTG6K"
   },
   "source": [
    "# CS108/212 STAT108/212 W26 Course Project\n",
    "\n",
    "### Team Details\n",
    "\n",
    "- Teammate 1: Henry Yost\n",
    "- Teammate 2: Dmitry Sorokin\n",
    "- Teammate 3: Kyle Chahal\n",
    "- Teammate 4: Refugio Zepeda\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Milestone: Mitigating Bias\n",
    "For this project milestone, each teammate will implement bias mitigation strategies and assess pre and post bias mitigation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H61P2lQlNz1Q"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zcjl4O1GN24E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib (from -r ../requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/40/5ba7d4a3f80d39d409f21899972596bf62c8606f1406a825029649eaa439/matplotlib-2.2.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting seaborn (from -r ../requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/86/43b8c9138ef4c2a1c492fee92792c83c13799d0e2061ff810d3826d06cd1/seaborn-0.9.1-py2.py3-none-any.whl\n",
      "Collecting pandas (from -r ../requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting numpy (from -r ../requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting scikit-learn (from -r ../requirements.txt (line 5))\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/31/9f/042db462417451e81035c3d43b722e88450c628a33dfda69777a801b0d40/scikit_learn-0.20.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting fairlearn (from -r ../requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/21/e4d3c914674af57273b64e49d874d8cc20b1d1518044dc6d9179bbf5c334/fairlearn-0.2.0.tar.gz\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /data/class/classes/kchah005/.local/lib/python2.7/site-packages (from matplotlib->-r ../requirements.txt (line 1))\n",
      "Collecting subprocess32 (from matplotlib->-r ../requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 6.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib->-r ../requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10 in /data/class/classes/kchah005/.local/lib/python2.7/site-packages (from matplotlib->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: backports.functools-lru-cache in /data/class/classes/kchah005/.local/lib/python2.7/site-packages (from matplotlib->-r ../requirements.txt (line 1))\n",
      "Collecting pytz (from matplotlib->-r ../requirements.txt (line 1))\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r ../requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 11.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib->-r ../requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/78/cb9248b2289ec31e301137cedbe4ca503a74ca87f88cdbfd2f8be52323bf/kiwisolver-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl (93kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 11.5MB/s a 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.17.1 (from seaborn->-r ../requirements.txt (line 2))\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/24/40/11b12af7f322c1e20446c037c47344d89bab4922b8859419d82cf56d796d/scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 52kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /data/class/classes/kchah005/.local/lib/python2.7/site-packages (from kiwisolver>=1.0.1->matplotlib->-r ../requirements.txt (line 1))\n",
      "Installing collected packages: subprocess32, cycler, pytz, pyparsing, numpy, kiwisolver, matplotlib, scipy, pandas, seaborn, scikit-learn, fairlearn\n",
      "  Running setup.py install for subprocess32 ... \u001b[?25lerror\n",
      "    Complete output from command /bin/python2 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-ZCpzfR/subprocess32/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-pmv3rw-record/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-2.7\n",
      "    copying subprocess32.py -> build/lib.linux-x86_64-2.7\n",
      "    running build_ext\n",
      "    running build_configure\n",
      "    checking for gcc... gcc\n",
      "    checking whether the C compiler works... yes\n",
      "    checking for C compiler default output file name... a.out\n",
      "    checking for suffix of executables...\n",
      "    checking whether we are cross compiling... no\n",
      "    checking for suffix of object files... o\n",
      "    checking whether we are using the GNU C compiler... yes\n",
      "    checking whether gcc accepts -g... yes\n",
      "    checking for gcc option to accept ISO C89... none needed\n",
      "    checking how to run the C preprocessor... gcc -E\n",
      "    checking for grep that handles long lines and -e... /bin/grep\n",
      "    checking for egrep... /bin/grep -E\n",
      "    checking for ANSI C header files... yes\n",
      "    checking for sys/types.h... yes\n",
      "    checking for sys/stat.h... yes\n",
      "    checking for stdlib.h... yes\n",
      "    checking for string.h... yes\n",
      "    checking for memory.h... yes\n",
      "    checking for strings.h... yes\n",
      "    checking for inttypes.h... yes\n",
      "    checking for stdint.h... yes\n",
      "    checking for unistd.h... yes\n",
      "    checking for unistd.h... (cached) yes\n",
      "    checking fcntl.h usability... yes\n",
      "    checking fcntl.h presence... yes\n",
      "    checking for fcntl.h... yes\n",
      "    checking signal.h usability... yes\n",
      "    checking signal.h presence... yes\n",
      "    checking for signal.h... yes\n",
      "    checking sys/cdefs.h usability... yes\n",
      "    checking sys/cdefs.h presence... yes\n",
      "    checking for sys/cdefs.h... yes\n",
      "    checking for sys/types.h... (cached) yes\n",
      "    checking for sys/stat.h... (cached) yes\n",
      "    checking sys/syscall.h usability... yes\n",
      "    checking sys/syscall.h presence... yes\n",
      "    checking for sys/syscall.h... yes\n",
      "    checking for dirent.h that defines DIR... yes\n",
      "    checking for library containing opendir... none required\n",
      "    checking for pipe2... yes\n",
      "    checking for setsid... yes\n",
      "    checking whether dirfd is declared... yes\n",
      "    configure: creating ./config.status\n",
      "    config.status: creating _posixsubprocess_config.h\n",
      "    building '_posixsubprocess32' extension\n",
      "    creating build/temp.linux-x86_64-2.7\n",
      "    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python2.7 -c _posixsubprocess.c -o build/temp.linux-x86_64-2.7/_posixsubprocess.o\n",
      "    In file included from /usr/include/python2.7/pyconfig.h:6,\n",
      "                     from /usr/include/python2.7/Python.h:8,\n",
      "                     from _posixsubprocess.c:16:\n",
      "    /usr/include/python2.7/pyconfig-64.h:1232: warning: \"_POSIX_C_SOURCE\" redefined\n",
      "     #define _POSIX_C_SOURCE 200112L\n",
      "    \n",
      "    In file included from /usr/include/sys/cdefs.h:23,\n",
      "                     from _posixsubprocess.c:12:\n",
      "    /usr/include/features.h:265: note: this is the location of the previous definition\n",
      "     # define _POSIX_C_SOURCE 200809L\n",
      "    \n",
      "    In file included from /usr/include/python2.7/pyconfig.h:6,\n",
      "                     from /usr/include/python2.7/Python.h:8,\n",
      "                     from _posixsubprocess.c:16:\n",
      "    /usr/include/python2.7/pyconfig-64.h:1254: warning: \"_XOPEN_SOURCE\" redefined\n",
      "     #define _XOPEN_SOURCE 600\n",
      "    \n",
      "    In file included from /usr/include/sys/cdefs.h:23,\n",
      "                     from _posixsubprocess.c:12:\n",
      "    /usr/include/features.h:202: note: this is the location of the previous definition\n",
      "     # define _XOPEN_SOURCE 700\n",
      "    \n",
      "    gcc -pthread -shared -Wl,-z,relro -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld build/temp.linux-x86_64-2.7/_posixsubprocess.o -L/usr/lib64 -lpython2.7 -o build/lib.linux-x86_64-2.7/_posixsubprocess32.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-2.7/subprocess32.py -> /usr/lib64/python2.7/site-packages\n",
      "    error: [Errno 13] Permission denied: '/usr/lib64/python2.7/site-packages/subprocess32.py'\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[?25h\u001b[31mCommand \"/bin/python2 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-ZCpzfR/subprocess32/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-pmv3rw-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-ZCpzfR/subprocess32/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# [INSERT CODE HERE to install necessary packages]\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tXKU9aa5HPd"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CRQN7QJF5JUH"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2716ae58ce82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib.pyplot"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Add additional imports needed for your project here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V3zrVf11GUF"
   },
   "source": [
    "# Loading dataset\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uimn7Sde1Jp2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n",
      "No. of samples: 48842\n",
      "No. of features: 14\n"
     ]
    }
   ],
   "source": [
    "# Load your selected dataset\n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "\n",
    "# variable information \n",
    "print(adult.variables)\n",
    "\n",
    "# Making our data a pandas df\n",
    "adult_clean = pd.concat([X, y], axis=1)\n",
    "\n",
    "sensitive_feature_colname = ['age', 'sex', 'race', 'marital-status'] # sensitive feature name\n",
    "#age, sex, race, (marital status), \n",
    "\n",
    "# Make sensitive features-based group labels\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "\n",
    "# Print some stats\n",
    "print(f\"No. of samples: {X.shape[0]}\")\n",
    "print(f\"No. of features: {X.shape[1]}\")\n",
    "#print(f\"Group Counts: {dict(collections.Counter(group_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq2dMuD87D0f"
   },
   "source": [
    "# Preparing dataset\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mq3wYB1H7CXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples AFTER cleaning: 32561\n",
      "No. of features AFTER encoding: 12\n"
     ]
    }
   ],
   "source": [
    "# Some subset of following dataset preparation steps may be necessary depending on your dataset,\n",
    "# 1. Drop unnecessary features\n",
    "# 2. Handle missing data\n",
    "# 3. Encode categorical features\n",
    "# 4. Normalize numerical features\n",
    "# 5. Encode target (if your task is classification)\n",
    "\n",
    "\n",
    "\n",
    "#removing unwanted columns\n",
    "adult_clean = adult_clean.drop(columns = ['education', 'native-country'])\n",
    "#removing any empty values:\n",
    "adult_clean = adult_clean.dropna()\n",
    "#making income binary\n",
    "    #1 represents over 50 k\n",
    "mapping = {'>50K': 1, '<=50K': 0}\n",
    "adult_clean['income'] = adult_clean['income'].map(mapping)\n",
    "#updating sensitive labels\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "#factorizing non-numeric data:\n",
    "\n",
    "adult_clean['workclass_num'], unique_labels = pd.factorize(adult_clean['workclass'])\n",
    "adult_clean['marital-status_num'], unique_labels = pd.factorize(adult_clean['marital-status'])\n",
    "adult_clean['occupation_num'], unique_labels = pd.factorize(adult_clean['occupation'])\n",
    "adult_clean['relationship_num'], unique_labels = pd.factorize(adult_clean['relationship'])\n",
    "adult_clean['race_num'], unique_labels = pd.factorize(adult_clean['race'])\n",
    "#For sex, male is 1, female is 0\n",
    "mapping = {'Male': 1, 'Female': 0}\n",
    "adult_clean['sex'] = adult_clean['sex'].map(mapping)\n",
    "\n",
    "adult_clean = adult_clean.dropna()\n",
    "\n",
    "X = adult_clean[['age', 'workclass_num', 'fnlwgt', 'education-num', 'marital-status_num', 'occupation_num', 'relationship_num', 'race_num', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']]\n",
    "y = adult_clean[['income']]\n",
    "\n",
    "group_labels = adult_clean[sensitive_feature_colname]\n",
    "\n",
    "\n",
    "# Note: X and y have been modified before the following lines of code!\n",
    "print(f\"No. of samples AFTER cleaning: {X.shape[0]}\")\n",
    "assert X.shape[0] == y.shape[0] == group_labels.shape[0] ## Ensure that the target and group_labels have been updated if some samples were removed during cleaning.\n",
    "print(f\"No. of features AFTER encoding: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1xfwjUT3nJ0"
   },
   "source": [
    "# Getting training and testing sets\n",
    "\n",
    "Note: Train-test split is made **ONCE** to obtain the _training set_ and the _testing set_ and every teammate will use the training set to train their baseline model and test the trained model using the testing set. **NEVER** modify the testing set once it has been created.\n",
    "Therefore, the following code cell does not need to be edited.\n",
    "\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udqlgotu5a5m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training samples: 26048\n",
      "No. of testing samples: 6513\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, \\\n",
    "  y_train, y_test, \\\n",
    "    group_labels_train, group_labels_test = train_test_split(X, y, group_labels,\n",
    "                                                             test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"No. of training samples: {X_train.shape[0]}\")\n",
    "print(f\"No. of testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Delete X, y and group_label variables to make sure they are not used later on.\n",
    "del X\n",
    "del y\n",
    "del group_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stfLke4NBA-B"
   },
   "source": [
    "# Setting up evaluation metrics\n",
    "Note: The same evaluation function will be used by all teammates.\n",
    "\n",
    "_(same as previous milestone, copy-paste)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RxX61lMDA50u"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-deeae24253a0>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-deeae24253a0>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    print(f\"Global Accuracy score of: {global_accuracy}\")\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# double importing just in case\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(y_test, y_pred, g_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of your trained model on the testing set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : array-like\n",
    "    The true targets of the testing set.\n",
    "    y_pred : array-like\n",
    "    The predicted targets of the testing set.\n",
    "    g_labels : array-like\n",
    "    The group labels of the testing set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "    A dictionary containing the evaluation results.\n",
    "    \n",
    "    Example:\n",
    "    For classification task, the task-specific performance metrics like {'accuracy': <value>, 'f1_score': <value>, ...}\n",
    "    and fairness metrics like {'demographic_parity': <value>, 'equalized_odds': <value>, ...}.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # force them to be arrays just in case, so we don't have an error\n",
    "    y_test = np.asarray(y_test).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    g_labels = np.asarray(g_labels).ravel()\n",
    "    \n",
    "    # Note: These metrics will be calculated for - 1. the full testing set, 2. individual groups.\n",
    "    # Task-specific performance metrics\n",
    "\n",
    "    global_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Global Accuracy score of: {global_accuracy}\")\n",
    "    results[\"accuracy_overall\"] = global_accuracy\n",
    "\n",
    "    global_f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Global f1 score of: {global_f1}\")\n",
    "    results[\"f1_overall\"] = global_f1\n",
    "\n",
    "    results[\"accuracy_by_group\"] = {}\n",
    "    results[\"f1_by_group\"] = {}\n",
    "\n",
    "    for g in np.unique(g_labels):\n",
    "        mask = (g_labels == g)\n",
    "        y_test_g = y_test[mask]\n",
    "        y_pred_g = y_pred[mask]\n",
    "\n",
    "        results[\"accuracy_by_group\"][g] = accuracy_score(y_test_g, y_pred_g)\n",
    "        results[\"f1_by_group\"][g] = f1_score(y_test_g, y_pred_g, pos_label=1, zero_division=0)\n",
    "    \n",
    "    # Fairness metric:\n",
    "    # The fairness metric we will be using is equalied odds, because: Equalized odds requires the TPR and FPR are equal accross all protected groups.\n",
    "\n",
    "    eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=g_labels, method='between_groups')\n",
    "    print(f\"Equalized Odds Difference: {eo_diff}\")\n",
    "    results['eo_diff'] = eo_diff\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My_giZbvpFEK"
   },
   "source": [
    "# Training baseline models (INDIVIDUAL CONTRIBUTION)\n",
    "_(minor modifications from previous milestone)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK2P9uZnIKGf"
   },
   "outputs": [],
   "source": [
    "## A place to save all teammates's baseline results\n",
    "all_baseline_results = [] ## DO NOT EDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "400FpWHZ_z0S"
   },
   "source": [
    "## Teammate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjKUAk4I_4DQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fc5e9578df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. Bin the ages from X_test ON THE FLY into a temporary variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbinned_age_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mage_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mage_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 3. Create your group_labels_test by combining the temporary binned ages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "# Deciding to use a KNN model\n",
    "#\n",
    "#defining sensitive cols\n",
    "age_bins = [0, 25, 45, 65, 120]\n",
    "age_labels = ['Under_25', '25_to_45', '46_to_65', 'Over_65']\n",
    "\n",
    "# 2. Bin the ages from X_test ON THE FLY into a temporary variable\n",
    "binned_age_test = pd.cut(X_test['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# 3. Create your group_labels_test by combining the temporary binned ages \n",
    "# with the other numerical columns in X_test\n",
    "group_labels_test = binned_age_test.astype(str) + '_' + \\\n",
    "                    X_test['sex'].astype(str) + '_' + \\\n",
    "                    X_test['race_num'].astype(str)\n",
    "\n",
    "# sensitive_cols = ['age', 'sex', 'race_num', 'marital-status_num']\n",
    "\n",
    "# # Setting group_labels_test\n",
    "# group_labels_test = X_test[sensitive_cols].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "#normalizing training data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#finding optimal number of neighbors from 1 to 10, arbitrarily chosen, to limit processing time.\n",
    "optimal_n = 0\n",
    "optimal_n_score = 0\n",
    "\n",
    "for i in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, np.asarray(y_train).ravel())\n",
    "    predictions = knn.predict(X_test)\n",
    "    model_score = eo_diff = equalized_odds_difference(y_test, predictions, sensitive_features=group_labels_test, method='between_groups')\n",
    "    #knn.score(X_test, y_test)\n",
    "\n",
    "    if(0 == optimal_n):\n",
    "        optimal_n = i\n",
    "        optimal_n_score = model_score\n",
    "    elif(model_score < optimal_n_score):\n",
    "        optimal_n = i\n",
    "        optimal_n_score = model_score\n",
    "\n",
    "    print('Neighbors: ', i, ' Equalized Odds Diff: ', model_score)\n",
    "\n",
    "#Making the actual model:\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=optimal_n)\n",
    "KNN_model.fit(X_train, np.asarray(y_train).ravel())\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = KNN_model.predict(X_test)\n",
    "print(\"Optimal number of neighbors: \", optimal_n, \". Optimal EO_diff: \", optimal_n_score)\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Dmitry'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'KNN' #[INSERT MODEL NAME HERE]\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VYWPshD_zlw"
   },
   "source": [
    "## Teammate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgDw0Ta7_7FT"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "decisionTree_Model = DecisionTreeClassifier(random_state = 44,\n",
    "                                            max_depth = 5,\n",
    "                                            min_samples_leaf = 20)\n",
    "\n",
    "decisionTree_Model.fit(X_train, np.asarray(y_train).ravel())\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = decisionTree_Model.predict(X_test)\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Kyle'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'Decision Tree' #[INSERT MODEL NAME HERE]\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bq--e_8_7o2"
   },
   "source": [
    "## Teammate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9DspEoL_-EV"
   },
   "outputs": [],
   "source": [
    "# Select a model and train it on the training set\n",
    "# [INSERT YOUR CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Teammate 3'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXm38f8ZABN3"
   },
   "source": [
    "## Teammate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-GVw7gOADZx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy score of: 0.8261937663135268\n",
      "Global f1 score of: 0.5574667709147771\n",
      "Equalized Odds Difference: 0.8333333333333334\n",
      "{'accuracy_by_group': {'25_to_45_0_0': 0.8469387755102041,\n",
      "                       '25_to_45_0_1': 0.9818181818181818,\n",
      "                       '25_to_45_0_2': 0.7777777777777778,\n",
      "                       '25_to_45_0_3': 1.0,\n",
      "                       '25_to_45_0_4': 1.0,\n",
      "                       '25_to_45_1_0': 0.7604698672114403,\n",
      "                       '25_to_45_1_1': 0.845679012345679,\n",
      "                       '25_to_45_1_2': 0.7159090909090909,\n",
      "                       '25_to_45_1_3': 0.9130434782608695,\n",
      "                       '25_to_45_1_4': 0.8947368421052632,\n",
      "                       '46_to_65_0_0': 0.8616504854368932,\n",
      "                       '46_to_65_0_1': 0.953125,\n",
      "                       '46_to_65_0_2': 0.9,\n",
      "                       '46_to_65_0_3': 0.8333333333333334,\n",
      "                       '46_to_65_0_4': 1.0,\n",
      "                       '46_to_65_1_0': 0.713903743315508,\n",
      "                       '46_to_65_1_1': 0.8333333333333334,\n",
      "                       '46_to_65_1_2': 0.7272727272727273,\n",
      "                       '46_to_65_1_3': 0.75,\n",
      "                       '46_to_65_1_4': 0.6666666666666666,\n",
      "                       'Over_65_0_0': 0.9253731343283582,\n",
      "                       'Over_65_0_1': 1.0,\n",
      "                       'Over_65_0_2': 1.0,\n",
      "                       'Over_65_0_4': 1.0,\n",
      "                       'Over_65_1_0': 0.725925925925926,\n",
      "                       'Over_65_1_1': 0.7272727272727273,\n",
      "                       'Over_65_1_2': 0.75,\n",
      "                       'Over_65_1_3': 1.0,\n",
      "                       'Under_25_0_0': 0.9804347826086957,\n",
      "                       'Under_25_0_1': 1.0,\n",
      "                       'Under_25_0_2': 0.9166666666666666,\n",
      "                       'Under_25_0_3': 1.0,\n",
      "                       'Under_25_0_4': 1.0,\n",
      "                       'Under_25_1_0': 0.9802130898021308,\n",
      "                       'Under_25_1_1': 0.9795918367346939,\n",
      "                       'Under_25_1_2': 0.9473684210526315,\n",
      "                       'Under_25_1_3': 1.0,\n",
      "                       'Under_25_1_4': 1.0},\n",
      " 'accuracy_overall': 0.8261937663135268,\n",
      " 'eo_diff': 0.8333333333333334,\n",
      " 'experiment_type': 'baseline',\n",
      " 'f1_by_group': {'25_to_45_0_0': 0.24050632911392406,\n",
      "                 '25_to_45_0_1': 0.5714285714285714,\n",
      "                 '25_to_45_0_2': 0.0,\n",
      "                 '25_to_45_0_3': 0.0,\n",
      "                 '25_to_45_0_4': 0.0,\n",
      "                 '25_to_45_1_0': 0.5295887662988967,\n",
      "                 '25_to_45_1_1': 0.4444444444444444,\n",
      "                 '25_to_45_1_2': 0.5901639344262295,\n",
      "                 '25_to_45_1_3': 0.8333333333333334,\n",
      "                 '25_to_45_1_4': 0.5,\n",
      "                 '46_to_65_0_0': 0.45714285714285713,\n",
      "                 '46_to_65_0_1': 0.4,\n",
      "                 '46_to_65_0_2': 0.0,\n",
      "                 '46_to_65_0_3': 0.6666666666666666,\n",
      "                 '46_to_65_0_4': 0.0,\n",
      "                 '46_to_65_1_0': 0.6595970307529162,\n",
      "                 '46_to_65_1_1': 0.6829268292682927,\n",
      "                 '46_to_65_1_2': 0.75,\n",
      "                 '46_to_65_1_3': 0.0,\n",
      "                 '46_to_65_1_4': 0.4,\n",
      "                 'Over_65_0_0': 0.2857142857142857,\n",
      "                 'Over_65_0_1': 0.0,\n",
      "                 'Over_65_0_2': 0.0,\n",
      "                 'Over_65_0_4': 0.0,\n",
      "                 'Over_65_1_0': 0.6105263157894737,\n",
      "                 'Over_65_1_1': 0.0,\n",
      "                 'Over_65_1_2': 0.0,\n",
      "                 'Over_65_1_3': 0.0,\n",
      "                 'Under_25_0_0': 0.0,\n",
      "                 'Under_25_0_1': 0.0,\n",
      "                 'Under_25_0_2': 0.0,\n",
      "                 'Under_25_0_3': 0.0,\n",
      "                 'Under_25_0_4': 0.0,\n",
      "                 'Under_25_1_0': 0.3157894736842105,\n",
      "                 'Under_25_1_1': 0.0,\n",
      "                 'Under_25_1_2': 0.0,\n",
      "                 'Under_25_1_3': 0.0,\n",
      "                 'Under_25_1_4': 0.0},\n",
      " 'f1_overall': 0.5574667709147771,\n",
      " 'mitigation_strategy': 'NONE',\n",
      " 'predictor_model': 'Logistic Regression',\n",
      " 'teammate': 'Refugio'}\n"
     ]
    }
   ],
   "source": [
    "# Select a model and train it on the training set\n",
    "# [INSERT YOUR CODE HERE]\n",
    "logreg = LogisticRegression(\n",
    "    C=1.0, \n",
    "    solver =\"lbfgs\",\n",
    "    max_iter= 1000 \n",
    ")\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results = evaluate_model(y_test, y_pred, group_labels_test)\n",
    "\n",
    "# Save your results to all_baseline_results\n",
    "results['teammate'] = 'Refugio'\n",
    "results['experiment_type'] = 'baseline'\n",
    "results['predictor_model'] = 'Logistic Regression'\n",
    "results['mitigation_strategy'] = 'NONE' ## DO NOT EDIT: This is pre-mitigation baseline\n",
    "all_baseline_results.append(results)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lq5X0Xb5eWA"
   },
   "source": [
    "# Mitigating Bias (INDIVIDUAL CONTRIBUTION)\n",
    "\n",
    "_(new in this milestone)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwfT5Uv9I0j6"
   },
   "outputs": [],
   "source": [
    "## A place to save all teammates' post-mitigation results\n",
    "all_mitigated_results = [] ## DO NOT EDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmQrfFvn6E85"
   },
   "source": [
    "## Teammate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZhAOHFB5lzh"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 1'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "pprint(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X05x8kjr6KrH"
   },
   "source": [
    "### Teammate 1's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLB2ggUCBen_"
   },
   "source": [
    "## Teammate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtbctHpBBgna"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 2'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmwKk9f2BlaM"
   },
   "source": [
    "### Teammate 2's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUpxtxuUCF_I"
   },
   "source": [
    "## Teammate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KlNlq7lCInQ"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 3'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YN7oELoCKmF"
   },
   "source": [
    "### Teammate 3's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qNMlhiECMcD"
   },
   "source": [
    "## Teammate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-JCVhRdCPSw"
   },
   "outputs": [],
   "source": [
    "# Implement your bias mitigation strategy\n",
    "## If you chose preprocessing, you will train a new version of your predictor model with new/modified inputs.\n",
    "## If you chose inprocessing, you will train a new version of your predictor with modified learning objective (loss function).\n",
    "## If you chose postprocessing, you will implement strategies to modify the predictions (y_pred) of the trained baseline predictor model from the previous milestone without training any new version of the predictor model.\n",
    "\n",
    "# [INSERT CODE HERE]\n",
    "\n",
    "# Make predictions on the testing set and store them in y_pred_mitigate\n",
    "y_pred_mitigated = ... # [INSERT CODE HERE]\n",
    "\n",
    "# Evaluate testing set predictions using evaluate_model()\n",
    "results_mitigated = evaluate_model(y_test, y_pred_mitigated, group_labels_test)\n",
    "\n",
    "# Save your results to all_mitigated_results\n",
    "results_mitigated['teammate'] = 'Teammate 4'\n",
    "results_mitigated['experiment_type'] = 'post-mitigation'\n",
    "results_mitigated['predictor_model'] = ... #[INSERT MODEL NAME HERE]\n",
    "results_mitigated['mitigation_strategy'] = ... #[INSERT STRATEGY TYPE HERE: 'preprocessing', 'inprocessing', 'postprocessing']\n",
    "all_mitigated_results.append(results_mitigated)\n",
    "\n",
    "print(results_mitigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnJcnOevCSm-"
   },
   "source": [
    "### Teammate 4's Conclusions\n",
    "[Briefly describe findings and conclusions here. Compare post-mitigation results with baseline results for your model. What is the % improvement in performance post-mitigation?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4LK5WRD7LvV"
   },
   "source": [
    "# Conclusions\n",
    "_(new in this milestone)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ZAgZJYf7F70N",
    "outputId": "42dcf95b-699c-4037-bb88-2c604648d111"
   },
   "outputs": [],
   "source": [
    "# Collect all the results in one table.\n",
    "overall_results = pd.concat([pd.DataFrame(all_baseline_results), pd.DataFrame(all_mitigated_results)])\n",
    "overall_results ## Note: The table displayed below in this starter notebook is for your reference, your team's table will be slightly different (e.g. different metrics, no.of sensitive attribute-based groups, actual values, etc.) upon successful completion of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds54O8vGGAEw"
   },
   "source": [
    "[Briefly describe overall findings and conclusions here. Which mitigation strategy resulted in most improvement? Which resulted in the least improvement? Visualize the results with some informative plots. (Hint: Use the `overall_results` table).]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-8NLvIOsPL-"
   },
   "source": [
    "# References\n",
    "\n",
    "[List the references you used to complete this milestone here.]\n",
    "- Teammate 1:\n",
    "- Teammate 2:\n",
    "- Teammate 3:\n",
    "- Teammate 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV3LsIXqKAg1"
   },
   "source": [
    "# Disclosures\n",
    "\n",
    "[Disclose use of generative AI and similar tools here.]\n",
    "- Teammate 1:\n",
    "- Teammate 2:\n",
    "- Teammate 3:\n",
    "- Teammate 4:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7V3zrVf11GUF",
    "zq2dMuD87D0f",
    "h1xfwjUT3nJ0",
    "stfLke4NBA-B",
    "400FpWHZ_z0S",
    "_VYWPshD_zlw",
    "_Bq--e_8_7o2",
    "DXm38f8ZABN3",
    "ZLB2ggUCBen_",
    "ZUpxtxuUCF_I",
    "3qNMlhiECMcD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
